{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Example of Estimator for CNN-based text classification with DBpedia data.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "EMBEDDING_SIZE = 20\n",
    "N_FILTERS = 256\n",
    "WINDOW_SIZE = 20\n",
    "FILTER_SHAPE1 = [WINDOW_SIZE, EMBEDDING_SIZE]\n",
    "FILTER_SHAPE2 = [WINDOW_SIZE, N_FILTERS]\n",
    "POOLING_WINDOW = 4\n",
    "POOLING_STRIDE = 2\n",
    "n_words = 0\n",
    "MAX_LABEL = 4\n",
    "WORDS_FEATURE = 'words'  # Name of the input words feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(features, labels, mode):\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(\n",
    "        features[WORDS_FEATURE],\n",
    "        vocab_size=n_words,\n",
    "        embed_dim=EMBEDDING_SIZE)\n",
    "    word_vectors = tf.expand_dims(word_vectors, 3)\n",
    "    \n",
    "    with tf.variable_scope('CNN_Layer1'):\n",
    "        # Apply Convolution filtering on input sequence.\n",
    "        conv1 = tf.layers.conv2d(\n",
    "            word_vectors,\n",
    "            filters=N_FILTERS,\n",
    "            kernel_size=FILTER_SHAPE1,\n",
    "            padding='VALID',\n",
    "            # Add a ReLU for non linearity.\n",
    "            activation=tf.nn.relu)\n",
    "        # Max pooling across output of Convolution+Relu.\n",
    "        pool1 = tf.layers.max_pooling2d(\n",
    "            conv1,\n",
    "            pool_size=POOLING_WINDOW,\n",
    "            strides=POOLING_STRIDE,\n",
    "            padding='SAME')\n",
    "        # Transpose matrix so that n_filters from convolution becomes width.\n",
    "        pool1 = tf.transpose(pool1, [0, 1, 3, 2])\n",
    "        \n",
    "    with tf.variable_scope('CNN_Layer2'):\n",
    "        # Second level of convolution filtering.\n",
    "        conv2 = tf.layers.conv2d(\n",
    "            pool1,\n",
    "            filters=N_FILTERS,\n",
    "            kernel_size=FILTER_SHAPE2,\n",
    "            padding='VALID')\n",
    "        \n",
    "        # Max across each filter to get useful features for classification.\n",
    "        pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1])\n",
    "        \n",
    "    # Apply regular WX + B and classification.\n",
    "    logits = tf.layers.dense(pool2, MAX_LABEL, activation=None)\n",
    "    \n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\n",
    "                'class': predicted_classes,\n",
    "                'prob': tf.nn.softmax(logits)\n",
    "            })\n",
    "\n",
    "    onehot_labels = tf.one_hot(labels, MAX_LABEL, 1, 0)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels,\n",
    "        logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    eval_metric_ops = {'accuracy': tf.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=predicted_classes)}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss=loss,\n",
    "        eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoonjae/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_csv = pd.read_csv('pubmed_data/train.csv', sep='::', header=None)\n",
    "x_train = train_csv[1]\n",
    "y_train = train_csv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoonjae/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_csv = pd.read_csv('pubmed_data/test.csv', sep='::', header=None)\n",
    "x_test = test_csv[1]\n",
    "y_test = test_csv[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--test_with_fake_data',\n",
    "    default=False,\n",
    "    help='Test the example code with fake data.',\n",
    "    action='store_true')\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 14203\n"
     ]
    }
   ],
   "source": [
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "x_train = np.array(list(vocab_processor.fit_transform(x_train)))\n",
    "x_test = np.array(list(vocab_processor.transform(x_test)))\n",
    "n_words = len(vocab_processor.vocabulary_)\n",
    "print('Total words: %d' % n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio', '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_tf_random_seed': 1, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(model_fn=cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 1.11726\n",
      "INFO:tensorflow:Saving checkpoints for 36 into /var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 74 into /var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 177873.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x121704a20>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={WORDS_FEATURE: x_train},\n",
    "    y=y_train,\n",
    "    batch_size=len(x_train),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "classifier.train(input_fn=train_input_fn, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio/model.ckpt-100\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={WORDS_FEATURE: x_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "predictions = classifier.predict(input_fn=test_input_fn)\n",
    "y_predicted = np.array(list(p['class'] for p in predictions))\n",
    "y_predicted = y_predicted.reshape(np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (sklearn): 0.437158\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-05-04:24:59\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/xw/tcgt4j055nv_cgcjrgjx4tz00000gn/T/tmphe226eio/model.ckpt-100\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-05-04:25:00\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.437158, global_step = 100, loss = 380046.0\n",
      "Accuracy (tensorflow): 0.437158\n"
     ]
    }
   ],
   "source": [
    "# Score with sklearn.\n",
    "score = metrics.accuracy_score(y_test, y_predicted)\n",
    "print('Accuracy (sklearn): {0:f}'.format(score))\n",
    "\n",
    "# Score with tensorflow.\n",
    "scores = classifier.evaluate(input_fn=test_input_fn)\n",
    "print('Accuracy (tensorflow): {0:f}'.format(scores['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.append(\n",
    "    {'MAX_DOCUMENT_LENGTH':MAX_DOCUMENT_LENGTH,\n",
    "     'EMBEDDING_SIZE':EMBEDDING_SIZE,\n",
    "     'N_FILTERS':N_FILTERS,\n",
    "     'WINDOW_SIZE':WINDOW_SIZE,\n",
    "     'POOLING_WINDOW':POOLING_WINDOW,\n",
    "     'POOLING_STRIDE':POOLING_STRIDE,\n",
    "     'n_words':n_words,\n",
    "     'accuracy':scores['accuracy']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMBEDDING_SIZE</th>\n",
       "      <th>MAX_DOCUMENT_LENGTH</th>\n",
       "      <th>N_FILTERS</th>\n",
       "      <th>POOLING_STRIDE</th>\n",
       "      <th>POOLING_WINDOW</th>\n",
       "      <th>WINDOW_SIZE</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.431694</td>\n",
       "      <td>14203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.437158</td>\n",
       "      <td>14203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMBEDDING_SIZE  MAX_DOCUMENT_LENGTH  N_FILTERS  POOLING_STRIDE  \\\n",
       "0              20                  100        128               2   \n",
       "1              20                  100        256               2   \n",
       "\n",
       "   POOLING_WINDOW  WINDOW_SIZE  accuracy  n_words  \n",
       "0               4           20  0.431694    14203  \n",
       "1               4           20  0.437158    14203  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
